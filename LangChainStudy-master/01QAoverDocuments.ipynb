{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 01 langchain结合本地知识库问答案例\n",
    "https://python.langchain.com/docs/use_cases/question_answering/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (0.0.251)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (0.0.18)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: numpy<2,>=1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from langchain) (2.0.19)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-04T20:08:01.862026Z",
     "end_time": "2023-08-04T20:08:04.034389Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: requests>=2.20 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: colorama in e:\\pycharmproject\\langchainstudyproject\\venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: tqdm, openai\n",
      "Successfully installed openai-0.27.8 tqdm-4.65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-04T20:08:04.038392Z",
     "end_time": "2023-08-04T20:08:08.843390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=\"sk-y09fqxxxxxxxxxz9rA7fU\")#这里需要填入你的openai api key，这个api已经不可用"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-04T22:05:55.038770Z",
     "end_time": "2023-08-04T22:05:55.066278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip install openai chromadb tiktoken"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-04T21:38:13.338582Z",
     "end_time": "2023-08-04T21:40:09.506487Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sqlite 安装\n",
    "在 Windows 上安装 SQLite\n",
    "\n",
    "请访问 SQLite 下载页面[https://www.sqlite.org/download.html] ，从 Windows 区下载预编译的二进制文件。\n",
    "\n",
    "您需要下载 sqlite-tools-win32-*.zip 和 sqlite-dll-win64-*.zip 压缩文件。\n",
    "\n",
    "创建文件夹 C:\\sqlite，并在此文件夹下解压上面两个压缩文件，将得到 sqlite3.def、sqlite3.dll 和 sqlite3.exe 文件。\n",
    "\n",
    "添加 C:\\sqlite 到 PATH 环境变量，最后在命令提示符下，使用 sqlite3 命令，将显示如下结果。\n",
    "\n",
    "```shell\n",
    "C:\\>sqlite3\n",
    "SQLite version 3.7.15.2 2013-01-09 11:53:05\n",
    "Enter \".help\" for instructions\n",
    "Enter SQL statements terminated with a \";\"\n",
    "sqlite>\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 环境变量设置\n",
    "第一步，按下“win+r”键，打开运行框，\n",
    "\n",
    "第二步，输入命令“control system”,\n",
    "\n",
    "第三步，在控制面板主页，打开“高级系统设置”，\n",
    "\n",
    "第四步，在高级系统设置界面，选择“环境变量”选项，\n",
    "\n",
    "第五步，根据需求进行设置。\n",
    "\n",
    "### 如果遇到报错\n",
    "RuntimeError: Your system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\n",
    "Please visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\n",
    "请使用python3.10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"sk-y09xxxxxxxxxxx7fU\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-04T22:05:18.469533Z",
     "end_time": "2023-08-04T22:05:18.496960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'E:\\\\pycharmproject\\\\LangChainStudyProject\\\\venv\\\\Scripts'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.path.dirname(sys.executable)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-04T22:24:58.514891Z",
     "end_time": "2023-08-04T22:24:58.528889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#设置代理\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:10809'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:10809'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:22:20.341934Z",
     "end_time": "2023-08-05T18:22:20.387941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:22:23.154397Z",
     "end_time": "2023-08-05T18:22:43.382092Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "' Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be done using LLM with simple prompting, task-specific instructions, or human inputs. Tree of Thoughts (Yao et al. 2023) is an example of a task decomposition technique that explores multiple reasoning possibilities at each step and generates a tree structure.'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"What is Task Decomposition?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:22:56.940715Z",
     "end_time": "2023-08-05T18:22:59.934101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:24:31.040019Z",
     "end_time": "2023-08-05T18:24:32.784638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:25:26.401183Z",
     "end_time": "2023-08-05T18:25:26.425719Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "130"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:25:48.265193Z",
     "end_time": "2023-08-05T18:25:48.313874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nJune 23, 2023\\xa0·\\xa031 min\\xa0·\\xa0Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\", metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:25:54.923182Z",
     "end_time": "2023-08-05T18:25:54.970471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:27:06.307935Z",
     "end_time": "2023-08-05T18:27:10.341148Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:28:09.072610Z",
     "end_time": "2023-08-05T18:28:09.730911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:28:19.204815Z",
     "end_time": "2023-08-05T18:28:19.263485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What are the approaches to Task Decomposition?',\n 'result': 'The approaches to task decomposition include:\\n\\n1. Prompting with LLM: This approach involves using simple prompts to guide the model in decomposing the task into subgoals or steps. For example, the model can be prompted with instructions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\\n\\n2. Task-specific instructions: In this approach, task-specific instructions are provided to the model to guide the task decomposition process. For example, if the task is to write a novel, the model can be instructed to \"Write a story outline\" as a step in the task decomposition.\\n\\n3. Human inputs: Task decomposition can also be done with the help of human inputs. Humans can provide guidance and input to the model in breaking down the task into smaller and simpler steps.\\n\\nIt\\'s important to note that the context does not provide any additional approaches to task decomposition beyond these three.'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever())\n",
    "qa_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:30:19.107251Z",
     "end_time": "2023-08-05T18:30:29.269981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:32:43.574929Z",
     "end_time": "2023-08-05T18:32:43.589458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chat = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:32:54.150576Z",
     "end_time": "2023-08-05T18:32:54.181286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Some of the main ideas in self-reflection include:\\n1. Iterative improvement: Self-reflection allows autonomous agents to improve by refining past action decisions and correcting mistakes.\\n2. Trial and error: Self-reflection is crucial in real-world tasks where trial and error are inevitable.\\n3. Two-shot examples: Self-reflection is created by showing pairs of failed trajectories and ideal reflections for guiding future changes in the plan.\\n4. Working memory: Reflections are added to the agent's working memory, up to three, to be used as context for querying.\\n5. Performance evaluation: Self-reflection involves continuously reviewing and analyzing actions, self-criticizing behavior, and reflecting on past decisions and strategies to refine approaches.\\n6. Efficiency: Self-reflection encourages being smart and efficient, aiming to complete tasks in the least number of steps.\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat({\"question\": \"What are some of the main ideas in self-reflection?\"})\n",
    "result['answer']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:32:59.518982Z",
     "end_time": "2023-08-05T18:33:07.098766Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "\"The Reflexion paper handles self-reflection by showing two-shot examples to the Learning Language Model (LLM). Each example consists of a failed trajectory and an ideal reflection that guides future changes in the agent's plan. These reflections are then added to the agent's working memory, up to a maximum of three, to be used as context for querying the LLM. This allows the agent to iteratively improve its reasoning skills by refining past action decisions and correcting previous mistakes.\""
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat({\"question\": \"How does the Reflexion paper handle it?\"})\n",
    "result['answer']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-05T18:33:14.731615Z",
     "end_time": "2023-08-05T18:33:21.650949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
